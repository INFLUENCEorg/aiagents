parameters:
  all:
    # define the learning agent
    mode: 'train'
    load: false
    name: 'DQN_Test'
    algorithm: DQN
    port: 8000
    gui: false
    env_type: 'SUMO'
    scene: 'loop_network_dumb'
    tlphasesfile: 'sample.net.xml'
    max_steps: 2.0e+6
    max_episode_steps: 5.0e+3
    frame_height: 14
    frame_width: 14
    num_frames: 4
    skip_frames: 1
    num_epoch: 4
    gamma: 0.99
    lambda: 0.95
    learning_rate: 2.5e-4
    batch_size: 32
    memory_size: 30000
    train_frequency: 1
    save_frequency: 5.0e+4
    summary_frequency: 1.0e+4
    tensorboard: true
    iteration: -1
    episode: 0
    seedlist: [43, 44, 45]

    # DQN only
    freeze_interval: 30000
    double_dqn: True
    epsilon: 0.1

    # define the SUMO simulation scenario
    box_bottom_corner: [9, 13]
    box_top_corner: [65, 69]
    y_t: 6 # Yellow (traffic light) time
    resolutionInPixelsPerMeterX: 0.25
    resolutionInPixelsPerMeterY: 0.25
    car_tm: 6
    state_type: 'ldm_state' # The type of state to use as input for the network. ('bin' (Position Matrix), 'bin_light' (Position Light Matrix), 'value' (Value Matrix))
    scaling_factor: 10 # for rescaling reward
    fast: false
    speed_dev: 0.0 # Can be used to vary the speeds of cars, according to a normal distribution with mean 1 and standard deviation speed_dev (SUMOs default is 0.1)
    car_pr: 1.0
    route_segments: ['L67 L68 L61 L62 L63 L64 L65 L66 L67 L68 L61 L62 L63 L64 L65 L66 L67 L68 L61 L62 L63 L64 L65 L66 L67 L68 L61 L62 L63 L64 L65 L66 L67 L68 L61 L62',
'L63 L64 L65 L66 L67 L68 L61 L62 L63 L64 L65 L66 L67 L68 L61 L62 L63 L64 L65 L66 L67 L68 L61 L62 L63 L64 L65 L66 L67 L68 L61 L62 L63 L64 L65 L66 L67 L68 L61 L62 L63 L64 L65 L66']
    route_starts: []
    route_ends: []
    route_max_segments: 1
    route_min_segments: 1
    local_rewards: True
    waiting_penalty: False
    lightPositions: {"0": [[37.5,44.16], [39.2,44.16], [32.5,37.5], [32.5,39.16]]}
